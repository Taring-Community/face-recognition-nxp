{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "c_-WFh3oiP1Q"
      },
      "source": [
        "# ONNX to TF-Lite Model Conversion"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-XwsxCL7iP1V"
      },
      "source": [
        "### Configure Paths\n",
        "\n",
        "You can update these paths as necessary for your particular `.onnx` model. Change the value of `ONNX_MODEL_PATH` to the path of your `.onnx` model file.\n",
        "\n",
        "``` python\n",
        "ONNX_MODEL_PATH = <path to your onnx model>\n",
        "```\n",
        "\n",
        "Change the value of `WORKING_DIR` to the path of the directory where you want to save conversion results.\n",
        "\n",
        "``` python\n",
        "WORKING_DIR = <path to your working directory>\n",
        "```\n",
        "\n",
        "__NOTE:__ You can view the contents of the `.onnx` model file by dragging and dropping onto the webapge: [netron.app](https://netron.app/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MQ5BPkMiP1V",
        "outputId": "90467298-dc1f-4f68-cfa2-dcb093b65fce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ONNX_MODEL_PATH = models/version-RFB-320_without_postprocessing.onnx\n",
            "MODEL_NAME = version-RFB-320_without_postprocessing\n",
            "WORKING_DIR = /tmp/root/mltk/ultra_light_onnx_to_tflite\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from mltk.utils.path import create_tempdir\n",
        "\n",
        "# This contains the path to the pre-trained model in ONNX model format\n",
        "# For this tutorial, we use the one downloaded from above\n",
        "# Update this path to point to your specific model if necessary\n",
        "ONNX_MODEL_PATH = os.path.join('../models/onnx/version-RFB-320_without_postprocessing.onnx')\n",
        "assert os.path.exists(ONNX_MODEL_PATH), f'The provided ONNX_MODEL_PATH does not exist at: {ONNX_MODEL_PATH}'\n",
        "\n",
        "# This contains the path to our working directory where all\n",
        "# generated, intermediate files will be stored.\n",
        "# For this tutorial, we use a temp directory.\n",
        "# Update as necessary for your setup\n",
        "WORKING_DIR = os.path.join('../models/results')\n",
        "if not os.path.exists(WORKING_DIR):\n",
        "    os.makedirs(WORKING_DIR, exist_ok=True)\n",
        "\n",
        "# Use the filename for the model's name\n",
        "MODEL_NAME = os.path.basename(ONNX_MODEL_PATH)[:-len('.onnx')]\n",
        "\n",
        "print(f'ONNX_MODEL_PATH = {ONNX_MODEL_PATH}')\n",
        "print(f'MODEL_NAME = {MODEL_NAME}')\n",
        "print(f'WORKING_DIR = {WORKING_DIR}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-P0IM7WoiP1W"
      },
      "source": [
        "### Simplify the ONNX model\n",
        "\n",
        "While optional, this step can help reduce the complexity of the ONNX \n",
        "by using the [ONNX Simplifier](https://github.com/daquexian/onnx-simplifier) Python package.\n",
        "\n",
        "This can help reduce the execution overhead on the embedded device.\n",
        "\n",
        "__NOTE:__ You can view the contents of the generated `.onnx` model file by dragging and dropping onto the webapge: [netron.app](https://netron.app/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWXqZdwLiP1W",
        "outputId": "486f9fd7-1f92-42fc-bf6f-03364f89c2ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating /tmp/root/mltk/ultra_light_onnx_to_tflite/version-RFB-320_without_postprocessing.simplified.onnx ...\n",
            "done\n"
          ]
        }
      ],
      "source": [
        "import onnxsim\n",
        "import onnx\n",
        "\n",
        "simplified_onnx_model, success = onnxsim.simplify(ONNX_MODEL_PATH)\n",
        "assert success, 'Failed to simplify the ONNX model. You may have to skip this step'\n",
        "simplified_onnx_model_path =  f'{WORKING_DIR}/{MODEL_NAME}.simplified.onnx'\n",
        "\n",
        "print(f'Generating {simplified_onnx_model_path} ...')\n",
        "onnx.save(simplified_onnx_model, simplified_onnx_model_path)\n",
        "print('done')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCpvZlVGiP1W"
      },
      "source": [
        "### Convert to OpenVino Intermediate Format\n",
        "\n",
        "Recall that the ONNX format uses the `NCHW` format while TF-Lite uses the `NHWC` format to store the model tensors.  \n",
        "While doable, converting from one format to the other is non-trivial. As such, additional steps are required to do the conversion.\n",
        "\n",
        "The first step is converting the `.onnx` model to the [OpenVino](https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html) intermediate format.  \n",
        "This is done using the tools installed by the [openvino_dev](https://pypi.org/project/openvino-dev/) Python package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Chq4tuRQiP1W",
        "outputId": "b3fcb059-1133-41d1-b7f3-64247374433d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating openvino at: /tmp/root/mltk/ultra_light_onnx_to_tflite/openvino\n",
            "[ WARNING ]  Use of deprecated cli option --data_type detected. Option use in the following releases will be fatal. \n",
            "[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.\n",
            "Find more information about API v2.0 and IR v11 at https://docs.openvino.ai/latest/openvino_2_0_transition_guide.html\n",
            "[ SUCCESS ] Generated IR version 11 model.\n",
            "[ SUCCESS ] XML file: /tmp/root/mltk/ultra_light_onnx_to_tflite/openvino/version-RFB-320_without_postprocessing.simplified.xml\n",
            "[ SUCCESS ] BIN file: /tmp/root/mltk/ultra_light_onnx_to_tflite/openvino/version-RFB-320_without_postprocessing.simplified.bin\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Import the model optimizer tool from the openvino_dev package\n",
        "from openvino.tools.mo import main as mo_main\n",
        "import onnx\n",
        "from onnx_tf.backend import prepare\n",
        "from mltk.utils.shell_cmd import run_shell_cmd\n",
        "\n",
        "# Load the ONNX model\n",
        "onnx_model = onnx.load(ONNX_MODEL_PATH)\n",
        "tf_rep = prepare(onnx_model)\n",
        "\n",
        "# Get the input tensor shape\n",
        "input_tensor = tf_rep.signatures[tf_rep.inputs[0]]\n",
        "input_shape = input_tensor.shape\n",
        "input_shape_str = '[' + ','.join([str(x) for x in input_shape]) + ']'\n",
        "\n",
        "\n",
        "openvino_out_dir = f'{WORKING_DIR}/openvino'\n",
        "os.makedirs(openvino_out_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "print(f'Generating openvino at: {openvino_out_dir}')\n",
        "cmd = [ \n",
        "    sys.executable, mo_main.__file__, \n",
        "    '--input_model', simplified_onnx_model_path,\n",
        "    '--input_shape', input_shape_str,\n",
        "    '--output_dir', openvino_out_dir,\n",
        "    '--data_type', 'FP32'\n",
        "\n",
        "]\n",
        "retcode, retmsg = run_shell_cmd(cmd,  outfile=sys.stdout)\n",
        "assert retcode == 0, 'Failed to do conversion' "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR1nFBAAiP1W"
      },
      "source": [
        "### Convert from OpenVino to TF-Lite-Float32 \n",
        "\n",
        "Next, we use the [openvino2tensorflow](https://github.com/PINTO0309/openvino2tensorflow) Python package to convert from the OpenVino intermediate format to a `.tflite` model file.  \n",
        "The generated model file has all of its weights and tensors in the __float32__ data type.\n",
        "\n",
        "__NOTE:__ You can view the contents of the `.tflite` model file by dragging and dropping onto the webapge: [netron.app](https://netron.app/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WhJFLQYiP1W",
        "outputId": "d0f52cba-0d91-459c-a105-343874107221"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating openvino2tensorflow model at: /tmp/root/mltk/ultra_light_onnx_to_tflite/openvino2tensorflow ...\n",
            "done\n"
          ]
        }
      ],
      "source": [
        "import os \n",
        "from mltk.utils.shell_cmd import run_shell_cmd\n",
        "\n",
        "openvino2tensorflow_out_dir = f'{WORKING_DIR}/openvino2tensorflow'\n",
        "openvino_xml_name = os.path.basename(simplified_onnx_model_path)[:-len('.onnx')] + '.xml'\n",
        "\n",
        "\n",
        "if os.name == 'nt':\n",
        "  openvino2tensorflow_exe_cmd = [sys.executable, os.path.join(os.path.dirname(sys.executable), 'openvino2tensorflow')]\n",
        "else:\n",
        "  openvino2tensorflow_exe_cmd = ['openvino2tensorflow']\n",
        "\n",
        "print(f'Generating openvino2tensorflow model at: {openvino2tensorflow_out_dir} ...')\n",
        "cmd = openvino2tensorflow_exe_cmd + [ \n",
        "    '--model_path', f'{openvino_out_dir}/{openvino_xml_name}',\n",
        "    '--model_output_path', openvino2tensorflow_out_dir,\n",
        "    '--output_saved_model',\n",
        "    '--output_no_quant_float32_tflite'\n",
        "]\n",
        "\n",
        "retcode, retmsg = run_shell_cmd(cmd)\n",
        "assert retcode == 0, retmsg\n",
        "print('done')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5Kj_ovleiP1X"
      },
      "source": [
        "### Prepare Representative Dataset\n",
        "\n",
        "For full integer quantization, you need to calibrate or estimate the range, i.e, (min, max) of all floating-point tensors in the model. Unlike constant tensors such as weights and biases, variable tensors such as model input, activations (outputs of intermediate layers) and model output cannot be calibrated unless we run a few inference cycles. As a result, the converter requires a representative dataset to calibrate them. \n",
        "\n",
        "This dataset can be a small subset (around ~100-500 samples) of the training or validation data. Refer to the representative_dataset() function below. Perform the following\n",
        "\n",
        "1. Download the dataset from this link: https://drive.google.com/file/d/1Db5Y_vdFzhqie-ibn_PXxbFkysslcE_6/view?usp=sharing (this is reduced to only contain test images and labels in widerface dataset)\n",
        "2. Unzip the file into folder `data` in the root directory if this project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMsfbeQ48sst"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import cv2\n",
        "\n",
        "def preprocess_image(img):\n",
        "    img_resize = cv2.resize(img, (320, 240))\n",
        "    img_resize = cv2.cvtColor(img_resize, cv2.COLOR_BGR2RGB)\n",
        "    img_resize = img_resize - 127.0\n",
        "    img_resize = img_resize / 128.0\n",
        "    img_resize = np.float32(np.expand_dims(img_resize, axis=0))\n",
        "\n",
        "    return img_resize\n",
        "\n",
        "\n",
        "def representative_dataset_generator():\n",
        "    folder = Path('data/wider_face_add_lm_10_10/JPEGImages')\n",
        "\n",
        "    i = 0\n",
        "    for p in folder.iterdir():\n",
        "        if p.is_dir():\n",
        "            continue\n",
        "        \n",
        "        if i > 1000:\n",
        "            break\n",
        "\n",
        "        img = cv2.imread(str(p))\n",
        "        i += 1\n",
        "        yield [preprocess_image(img)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Quantize the TF-Lite Model\n",
        "\n",
        "The final conversion step is converting the `.tflite` model file which has __float32__ tensors into a `.tflite` model file that has __int8__ tensors.\n",
        "A model with __int8__ tensors executes much more efficiently on an embedded device and also reduces the memory requirements by a factor of 4.\n",
        "\n",
        "This conversion process is called [Post-Training Quantization](https://www.tensorflow.org/lite/performance/post_training_quantization).  \n",
        "To do the conversion, we use the [TfliteConverter](https://www.tensorflow.org/lite/convert) that comes with Tensorflow.\n",
        "\n",
        "To do the quantization, we need a _representative dataset_. \n",
        "\n",
        "__NOTE:__ You can view the contents of the quantized `.tflite` model file by dragging and dropping onto the webapge: [netron.app](https://netron.app/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zft5O087iP1X",
        "outputId": "526e7dbc-6a7b-4140-bb6d-be080f342738"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating /tmp/root/mltk/ultra_light_onnx_to_tflite/version-RFB-320_without_postprocessing.int8.tflite ...\n",
            "done\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "\n",
        "tflite_int8_model_path = f'{WORKING_DIR}/{MODEL_NAME}.int8.tflite'\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(openvino2tensorflow_out_dir)\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8] # We only want to use int8 kernels\n",
        "converter.inference_input_type = tf.float32 # Can also be tf.int8\n",
        "converter.inference_output_type = tf.float32  # Can also be tf.int8\n",
        "converter.representative_dataset = representative_dataset_generator\n",
        "\n",
        "print(f'Generating {tflite_int8_model_path} ...')\n",
        "tflite_quant_model = converter.convert()\n",
        "\n",
        "with open(tflite_int8_model_path, 'wb') as f:\n",
        "    f.write(tflite_quant_model)\n",
        "\n",
        "print('done')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1MsVQ6UiP1X"
      },
      "source": [
        "## Profile the Quantized Model\n",
        "\n",
        "Now that we have converted the `.onnx` model to a quantized `.tflite` model, let's profile it to see if it can run on an embedded target.\n",
        "\n",
        "For this, we use the [Model Profiler](https://siliconlabs.github.io/mltk/docs/guides/model_profiler.html) that comes with the MLTK."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbOoasDgiP1X",
        "outputId": "f83820de-e82c-4fef-c559-9e70c6e8588e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Profiling model in simulator ...\n",
            "Profiling Summary\n",
            "Name: version-RFB-320_without_postprocessing_int8\n",
            "Accelerator: mvp\n",
            "Input Shape: 1x240x320x3\n",
            "Input Data Type: float32\n",
            "Output Shape: 1x4420x2,1x4420x4\n",
            "Output Data Type: float32,float32\n",
            "Flash, Model File Size (bytes): 411.2k\n",
            "RAM, Runtime Memory Size (bytes): 1.3M\n",
            "Operation Count: 223.6M\n",
            "Multiply-Accumulate Count: 100.4M\n",
            "Layer Count: 92\n",
            "Unsupported Layer Count: 21\n",
            "Accelerator Cycle Count: 15.5M\n",
            "\n",
            "Model Layers\n",
            "+-------+-------------------+--------+--------+------------+----------------------------------+--------------+-------------------------------------------------------+------------+---------------------------------------------------------------------+\n",
            "| Index | OpCode            | # Ops  | # MACs | Acc Cycles | Input Shape                      | Output Shape | Options                                               | Supported? | Error Msg                                                           |\n",
            "+-------+-------------------+--------+--------+------------+----------------------------------+--------------+-------------------------------------------------------+------------+---------------------------------------------------------------------+\n",
            "| 0     | quantize          | 921.6k | 0      | 0          | 1x240x320x3                      | 1x240x320x3  | Type=none                                             | True       |                                                                     |\n",
            "| 1     | pad               | 1.4M   | 0      | 0          | 1x240x320x3,4x2                  | 1x242x322x3  | Type=padoptions                                       | True       |                                                                     |\n",
            "| 2     | conv_2d           | 17.5M  | 8.3M   | 0          | 1x242x322x3,16x3x3x3,16          | 1x120x160x16 | Padding:Valid stride:2x2 activation:Relu              | False      | Output vector stride (2560) exceeded (max=2047)                     |\n",
            "| 3     | pad               | 1.9M   | 0      | 0          | 1x120x160x16,4x2                 | 1x122x162x16 | Type=padoptions                                       | True       |                                                                     |\n",
            "| 4     | depthwise_conv_2d | 6.5M   | 2.8M   | 0          | 1x122x162x16,1x3x3x16,16         | 1x120x160x16 | Multiplier:1 padding:Valid stride:1x1 activation:Relu | False      | output_stride[3] (2560) > 2047                                      |\n",
            "| 5     | conv_2d           | 21.5M  | 9.8M   | 0          | 1x120x160x16,32x1x1x16,32        | 1x120x160x32 | Padding:Valid stride:1x1 activation:Relu              | False      | Output vector stride (5120) exceeded (max=2047)                     |\n",
            "| 6     | pad               | 3.8M   | 0      | 0          | 1x120x160x32,4x2                 | 1x122x162x32 | Type=padoptions                                       | True       |                                                                     |\n",
            "| 7     | depthwise_conv_2d | 3.2M   | 1.4M   | 0          | 1x122x162x32,1x3x3x32,32         | 1x60x80x32   | Multiplier:1 padding:Valid stride:2x2 activation:Relu | False      | output_stride[3] (2560) > 2047                                      |\n",
            "| 8     | conv_2d           | 10.3M  | 4.9M   | 0          | 1x60x80x32,32x1x1x32,32          | 1x60x80x32   | Padding:Valid stride:1x1 activation:Relu              | False      | Output vector stride (2560) exceeded (max=2047)                     |\n",
            "| 9     | pad               | 976.1k | 0      | 0          | 1x60x80x32,4x2                   | 1x62x82x32   | Type=padoptions                                       | True       |                                                                     |\n",
            "| 10    | depthwise_conv_2d | 3.2M   | 1.4M   | 0          | 1x62x82x32,1x3x3x32,32           | 1x60x80x32   | Multiplier:1 padding:Valid stride:1x1 activation:Relu | False      | output_stride[3] (2560) > 2047                                      |\n",
            "| 11    | conv_2d           | 10.3M  | 4.9M   | 0          | 1x60x80x32,32x1x1x32,32          | 1x60x80x32   | Padding:Valid stride:1x1 activation:Relu              | False      | Output vector stride (2560) exceeded (max=2047)                     |\n",
            "| 12    | pad               | 976.1k | 0      | 0          | 1x60x80x32,4x2                   | 1x62x82x32   | Type=padoptions                                       | True       |                                                                     |\n",
            "| 13    | depthwise_conv_2d | 806.4k | 345.6k | 0          | 1x62x82x32,1x3x3x32,32           | 1x30x40x32   | Multiplier:1 padding:Valid stride:2x2 activation:Relu | False      | Assertion failed: (unsigned)strides[i] <= ((0xFFF0000UL >> (16+1))) |\n",
            "| 14    | conv_2d           | 5.1M   | 2.5M   | 0          | 1x30x40x32,64x1x1x32,64          | 1x30x40x64   | Padding:Valid stride:1x1 activation:Relu              | False      | Output vector stride (2560) exceeded (max=2047)                     |\n",
            "| 15    | pad               | 516.1k | 0      | 0          | 1x30x40x64,4x2                   | 1x32x42x64   | Type=padoptions                                       | True       |                                                                     |\n",
            "| 16    | depthwise_conv_2d | 1.6M   | 691.2k | 1.2M       | 1x32x42x64,1x3x3x64,64           | 1x30x40x64   | Multiplier:1 padding:Valid stride:1x1 activation:Relu | True       |                                                                     |\n",
            "| 17    | conv_2d           | 10.1M  | 4.9M   | 0          | 1x30x40x64,64x1x1x64,64          | 1x30x40x64   | Padding:Valid stride:1x1 activation:Relu              | False      | Output vector stride (2560) exceeded (max=2047)                     |\n",
            "| 18    | pad               | 516.1k | 0      | 0          | 1x30x40x64,4x2                   | 1x32x42x64   | Type=padoptions                                       | True       |                                                                     |\n",
            "| 19    | depthwise_conv_2d | 1.6M   | 691.2k | 1.2M       | 1x32x42x64,1x3x3x64,64           | 1x30x40x64   | Multiplier:1 padding:Valid stride:1x1 activation:Relu | True       |                                                                     |\n",
            "| 20    | conv_2d           | 10.1M  | 4.9M   | 0          | 1x30x40x64,64x1x1x64,64          | 1x30x40x64   | Padding:Valid stride:1x1 activation:Relu              | False      | Output vector stride (2560) exceeded (max=2047)                     |\n",
            "| 21    | conv_2d           | 1.2M   | 614.4k | 384.0k     | 1x30x40x64,8x1x1x64,8            | 1x30x40x8    | Padding:Valid stride:1x1 activation:None              | True       |                                                                     |\n",
            "| 22    | pad               | 64.5k  | 0      | 0          | 1x30x40x8,4x2                    | 1x32x42x8    | Type=padoptions                                       | True       |                                                                     |\n",
            "| 23    | conv_2d           | 2.8M   | 1.4M   | 773.4k     | 1x32x42x8,16x3x3x8,16            | 1x30x40x16   | Padding:Valid stride:1x1 activation:Relu              | True       |                                                                     |\n",
            "| 24    | pad               | 159.0k | 0      | 0          | 1x30x40x16,4x2                   | 1x36x46x16   | Type=padoptions                                       | True       |                                                                     |\n",
            "| 25    | conv_2d           | 5.5M   | 2.8M   | 0          | 1x36x46x16,16x3x3x16,16          | 1x30x40x16   | Padding:Valid stride:1x1 activation:None              | False      | Dilation not supported                                              |\n",
            "| 26    | conv_2d           | 1.2M   | 614.4k | 384.0k     | 1x30x40x64,8x1x1x64,8            | 1x30x40x8    | Padding:Valid stride:1x1 activation:None              | True       |                                                                     |\n",
            "| 27    | pad               | 64.5k  | 0      | 0          | 1x30x40x8,4x2                    | 1x32x42x8    | Type=padoptions                                       | True       |                                                                     |\n",
            "| 28    | conv_2d           | 2.1M   | 1.0M   | 581.4k     | 1x32x42x8,12x3x3x8,12            | 1x30x40x12   | Padding:Valid stride:1x1 activation:Relu              | True       |                                                                     |\n",
            "| 29    | pad               | 96.8k  | 0      | 0          | 1x30x40x12,4x2                   | 1x32x42x12   | Type=padoptions                                       | True       |                                                                     |\n",
            "| 30    | conv_2d           | 4.2M   | 2.1M   | 1.1M       | 1x32x42x12,16x3x3x12,16          | 1x30x40x16   | Padding:Valid stride:1x1 activation:Relu              | True       |                                                                     |\n",
            "| 31    | pad               | 192.0k | 0      | 0          | 1x30x40x16,4x2                   | 1x40x50x16   | Type=padoptions                                       | True       |                                                                     |\n",
            "| 32    | conv_2d           | 5.5M   | 2.8M   | 0          | 1x40x50x16,16x3x3x16,16          | 1x30x40x16   | Padding:Valid stride:1x1 activation:None              | False      | Dilation not supported                                              |\n",
            "| 33    | conv_2d           | 9.9M   | 4.9M   | 0          | 1x30x40x64,64x1x1x64,64          | 1x30x40x64   | Padding:Valid stride:1x1 activation:None              | False      | Output vector stride (2560) exceeded (max=2047)                     |\n",
            "| 34    | conv_2d           | 1.2M   | 614.4k | 384.0k     | 1x30x40x64,8x1x1x64,8            | 1x30x40x8    | Padding:Valid stride:1x1 activation:None              | True       |                                                                     |\n",
            "| 35    | pad               | 64.5k  | 0      | 0          | 1x30x40x8,4x2                    | 1x32x42x8    | Type=padoptions                                       | True       |                                                                     |\n",
            "| 36    | conv_2d           | 2.8M   | 1.4M   | 773.4k     | 1x32x42x8,16x3x3x8,16            | 1x30x40x16   | Padding:Valid stride:1x1 activation:Relu              | True       |                                                                     |\n",
            "| 37    | pad               | 143.6k | 0      | 0          | 1x30x40x16,4x2                   | 1x34x44x16   | Type=padoptions                                       | True       |                                                                     |\n",
            "| 38    | conv_2d           | 5.5M   | 2.8M   | 0          | 1x34x44x16,16x3x3x16,16          | 1x30x40x16   | Padding:Valid stride:1x1 activation:None              | False      | Dilation not supported                                              |\n",
            "| 39    | concatenation     | 0      | 0      | 0          | 1x30x40x16,1x30x40x16,1x30x40x16 | 1x30x40x48   | Type=concatenationoptions                             | True       |                                                                     |\n",
            "| 40    | conv_2d           | 7.4M   | 3.7M   | 0          | 1x30x40x48,64x1x1x48,64          | 1x30x40x64   | Padding:Valid stride:1x1 activation:None              | False      | Output vector stride (2560) exceeded (max=2047)                     |\n",
            "| 41    | add               | 76.8k  | 0      | 192.0k     | 1x30x40x64,1x30x40x64            | 1x30x40x64   | Activation:Relu                                       | True       |                                                                     |\n",
            "| 42    | pad               | 516.1k | 0      | 0          | 1x30x40x64,4x2                   | 1x32x42x64   | Type=padoptions                                       | True       |                                                                     |\n",
            "| 43    | depthwise_conv_2d | 1.6M   | 691.2k | 1.2M       | 1x32x42x64,1x3x3x64,64           | 1x30x40x64   | Multiplier:1 padding:Valid stride:1x1 activation:Relu | True       |                                                                     |\n",
            "| 44    | conv_2d           | 1.9M   | 921.6k | 556.8k     | 1x30x40x64,12x1x1x64,12          | 1x30x40x12   | Padding:Valid stride:1x1 activation:None              | True       |                                                                     |\n",
            "| 45    | reshape           | 0      | 0      | 0          | 1x30x40x12,3                     | 1x3600x4     | Type=none                                             | True       |                                                                     |\n",
            "| 46    | depthwise_conv_2d | 403.2k | 172.8k | 288.0k     | 1x32x42x64,1x3x3x64,64           | 1x15x20x64   | Multiplier:1 padding:Valid stride:2x2 activation:Relu | True       |                                                                     |\n",
            "| 47    | conv_2d           | 5.0M   | 2.5M   | 0          | 1x15x20x64,128x1x1x64,128        | 1x15x20x128  | Padding:Valid stride:1x1 activation:Relu              | False      | Output vector stride (2560) exceeded (max=2047)                     |\n",
            "| 48    | pad               | 287.2k | 0      | 0          | 1x15x20x128,4x2                  | 1x17x22x128  | Type=padoptions                                       | True       |                                                                     |\n",
            "| 49    | depthwise_conv_2d | 806.4k | 345.6k | 576.0k     | 1x17x22x128,1x3x3x128,128        | 1x15x20x128  | Multiplier:1 padding:Valid stride:1x1 activation:Relu | True       |                                                                     |\n",
            "| 50    | conv_2d           | 9.9M   | 4.9M   | 0          | 1x15x20x128,128x1x1x128,128      | 1x15x20x128  | Padding:Valid stride:1x1 activation:Relu              | False      | Output vector stride (2560) exceeded (max=2047)                     |\n",
            "| 51    | pad               | 287.2k | 0      | 0          | 1x15x20x128,4x2                  | 1x17x22x128  | Type=padoptions                                       | True       |                                                                     |\n",
            "| 52    | depthwise_conv_2d | 806.4k | 345.6k | 576.0k     | 1x17x22x128,1x3x3x128,128        | 1x15x20x128  | Multiplier:1 padding:Valid stride:1x1 activation:Relu | True       |                                                                     |\n",
            "| 53    | conv_2d           | 9.9M   | 4.9M   | 0          | 1x15x20x128,128x1x1x128,128      | 1x15x20x128  | Padding:Valid stride:1x1 activation:Relu              | False      | Output vector stride (2560) exceeded (max=2047)                     |\n",
            "| 54    | pad               | 287.2k | 0      | 0          | 1x15x20x128,4x2                  | 1x17x22x128  | Type=padoptions                                       | True       |                                                                     |\n",
            "| 55    | depthwise_conv_2d | 806.4k | 345.6k | 576.0k     | 1x17x22x128,1x3x3x128,128        | 1x15x20x128  | Multiplier:1 padding:Valid stride:1x1 activation:Relu | True       |                                                                     |\n",
            "| 56    | conv_2d           | 616.8k | 307.2k | 182.4k     | 1x15x20x128,8x1x1x128,8          | 1x15x20x8    | Padding:Valid stride:1x1 activation:None              | True       |                                                                     |\n",
            "| 57    | reshape           | 0      | 0      | 0          | 1x15x20x8,3                      | 1x600x4      | Type=none                                             | True       |                                                                     |\n",
            "| 58    | depthwise_conv_2d | 215.0k | 92.2k  | 153.6k     | 1x17x22x128,1x3x3x128,128        | 1x8x10x128   | Multiplier:1 padding:Valid stride:2x2 activation:Relu | True       |                                                                     |\n",
            "| 59    | conv_2d           | 5.3M   | 2.6M   | 0          | 1x8x10x128,256x1x1x128,256       | 1x8x10x256   | Padding:Valid stride:1x1 activation:Relu              | False      | Output vector stride (2560) exceeded (max=2047)                     |\n",
            "| 60    | pad               | 184.3k | 0      | 0          | 1x8x10x256,4x2                   | 1x10x12x256  | Type=padoptions                                       | True       |                                                                     |\n",
            "| 61    | depthwise_conv_2d | 430.1k | 184.3k | 307.2k     | 1x10x12x256,1x3x3x256,256        | 1x8x10x256   | Multiplier:1 padding:Valid stride:1x1 activation:Relu | True       |                                                                     |\n",
            "| 62    | conv_2d           | 10.5M  | 5.2M   | 0          | 1x8x10x256,256x1x1x256,256       | 1x8x10x256   | Padding:Valid stride:1x1 activation:Relu              | False      | Output vector stride (2560) exceeded (max=2047)                     |\n",
            "| 63    | conv_2d           | 2.6M   | 1.3M   | 686.1k     | 1x8x10x256,64x1x1x256,64         | 1x8x10x64    | Padding:Valid stride:1x1 activation:Relu              | True       |                                                                     |\n",
            "| 64    | pad               | 46.1k  | 0      | 0          | 1x8x10x64,4x2                    | 1x10x12x64   | Type=padoptions                                       | True       |                                                                     |\n",
            "| 65    | depthwise_conv_2d | 26.9k  | 11.5k  | 19.2k      | 1x10x12x64,1x3x3x64,64           | 1x4x5x64     | Multiplier:1 padding:Valid stride:2x2 activation:Relu | True       |                                                                     |\n",
            "| 66    | conv_2d           | 670.7k | 327.7k | 185.2k     | 1x4x5x64,256x1x1x64,256          | 1x4x5x256    | Padding:Valid stride:1x1 activation:Relu              | True       |                                                                     |\n",
            "| 67    | pad               | 64.5k  | 0      | 0          | 1x4x5x256,4x2                    | 1x6x7x256    | Type=padoptions                                       | True       |                                                                     |\n",
            "| 68    | conv_2d           | 1.1M   | 553.0k | 282.9k     | 1x6x7x256,12x3x3x256,12          | 1x4x5x12     | Padding:Valid stride:1x1 activation:None              | True       |                                                                     |\n",
            "| 69    | reshape           | 0      | 0      | 0          | 1x4x5x12,3                       | 1x60x4       | Type=none                                             | True       |                                                                     |\n",
            "| 70    | conv_2d           | 553.1k | 276.5k | 144.1k     | 1x6x7x256,6x3x3x256,6            | 1x4x5x6      | Padding:Valid stride:1x1 activation:None              | True       |                                                                     |\n",
            "| 71    | reshape           | 0      | 0      | 0          | 1x4x5x6,3                        | 1x60x2       | Type=none                                             | True       |                                                                     |\n",
            "| 72    | pad               | 184.3k | 0      | 0          | 1x8x10x256,4x2                   | 1x10x12x256  | Type=padoptions                                       | True       |                                                                     |\n",
            "| 73    | depthwise_conv_2d | 430.1k | 184.3k | 307.2k     | 1x10x12x256,1x3x3x256,256        | 1x8x10x256   | Multiplier:1 padding:Valid stride:1x1 activation:Relu | True       |                                                                     |\n",
            "| 74    | conv_2d           | 328.3k | 163.8k | 94.7k      | 1x8x10x256,8x1x1x256,8           | 1x8x10x8     | Padding:Valid stride:1x1 activation:None              | True       |                                                                     |\n",
            "| 75    | reshape           | 0      | 0      | 0          | 1x8x10x8,3                       | 1x160x4      | Type=none                                             | True       |                                                                     |\n",
            "| 76    | concatenation     | 0      | 0      | 0          | 1x3600x4,1x600x4,1x160x4,1x60x4  | 1x4420x4     | Type=concatenationoptions                             | True       |                                                                     |\n",
            "| 77    | dequantize        | 35.4k  | 0      | 0          | 1x4420x4                         | 1x4420x4     | Type=none                                             | True       |                                                                     |\n",
            "| 78    | depthwise_conv_2d | 430.1k | 184.3k | 307.2k     | 1x10x12x256,1x3x3x256,256        | 1x8x10x256   | Multiplier:1 padding:Valid stride:1x1 activation:Relu | True       |                                                                     |\n",
            "| 79    | conv_2d           | 164.2k | 81.9k  | 52.5k      | 1x8x10x256,4x1x1x256,4           | 1x8x10x4     | Padding:Valid stride:1x1 activation:None              | True       |                                                                     |\n",
            "| 80    | reshape           | 0      | 0      | 0          | 1x8x10x4,3                       | 1x160x2      | Type=none                                             | True       |                                                                     |\n",
            "| 81    | depthwise_conv_2d | 806.4k | 345.6k | 576.0k     | 1x17x22x128,1x3x3x128,128        | 1x15x20x128  | Multiplier:1 padding:Valid stride:1x1 activation:Relu | True       |                                                                     |\n",
            "| 82    | conv_2d           | 308.4k | 153.6k | 100.8k     | 1x15x20x128,4x1x1x128,4          | 1x15x20x4    | Padding:Valid stride:1x1 activation:None              | True       |                                                                     |\n",
            "| 83    | reshape           | 0      | 0      | 0          | 1x15x20x4,3                      | 1x600x2      | Type=none                                             | True       |                                                                     |\n",
            "| 84    | depthwise_conv_2d | 1.6M   | 691.2k | 1.2M       | 1x32x42x64,1x3x3x64,64           | 1x30x40x64   | Multiplier:1 padding:Valid stride:1x1 activation:Relu | True       |                                                                     |\n",
            "| 85    | conv_2d           | 928.8k | 460.8k | 297.6k     | 1x30x40x64,6x1x1x64,6            | 1x30x40x6    | Padding:Valid stride:1x1 activation:None              | True       |                                                                     |\n",
            "| 86    | reshape           | 0      | 0      | 0          | 1x30x40x6,3                      | 1x3600x2     | Type=none                                             | True       |                                                                     |\n",
            "| 87    | concatenation     | 0      | 0      | 0          | 1x3600x2,1x600x2,1x160x2,1x60x2  | 1x4420x2     | Type=concatenationoptions                             | True       |                                                                     |\n",
            "| 88    | reshape           | 0      | 0      | 0          | 1x4420x2,2                       | 4420x2       | Type=none                                             | True       |                                                                     |\n",
            "| 89    | softmax           | 10.0   | 0      | 0          | 4420x2                           | 4420x2       | Type=softmaxoptions                                   | True       |                                                                     |\n",
            "| 90    | reshape           | 0      | 0      | 0          | 4420x2,3                         | 1x4420x2     | Type=none                                             | True       |                                                                     |\n",
            "| 91    | dequantize        | 17.7k  | 0      | 0          | 1x4420x2                         | 1x4420x2     | Type=none                                             | True       |                                                                     |\n",
            "+-------+-------------------+--------+--------+------------+----------------------------------+--------------+-------------------------------------------------------+------------+---------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "from mltk.core import profile_model\n",
        "\n",
        "results = profile_model(\n",
        "    tflite_int8_model_path,\n",
        "    accelerator='mvp' # Optional profile using the MVP hardware accelerator\n",
        ")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOs4XgO3Z8pe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 ('.venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b39e588e0ae573fcdb2e236c5b2086e252de027cd9c62d4f2a4f218e81e6ab69"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
